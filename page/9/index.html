<!DOCTYPE html><html lang="zn-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>LZMcosmos</title><meta name="author" content="李子梅"><meta name="copyright" content="李子梅"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta property="og:type" content="website">
<meta property="og:title" content="LZMcosmos">
<meta property="og:url" content="https://lzmcosmos.github.io/page/9/index.html">
<meta property="og:site_name" content="LZMcosmos">
<meta property="og:locale" content="zn_CN">
<meta property="og:image" content="https://lzmcosmos.github.io/img/cosmos.jpg">
<meta property="article:author" content="李子梅">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://lzmcosmos.github.io/img/cosmos.jpg"><link rel="shortcut icon" href="/img/cosmos.jpg"><link rel="canonical" href="https://lzmcosmos.github.io/page/9/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="preconnect" href="//zz.bdstatic.com"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2022-03-14 09:54:44'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><meta name="generator" content="Hexo 5.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/cosmos.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">89</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">108</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">9</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div></div></div></div><div id="body-wrap"><header class="full_page" id="page-header" style="background-image: url(/img/Green_Planet_Space_Satellite_Universe.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LZMcosmos</a></span><span id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="site-info"><h1 id="site-title">LZMcosmos</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/LZMcosmos" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:609792588@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2020/11/25/Transformer/" title="Transformer">Transformer</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-25T02:57:22.000Z" title="Created 2020-11-25 10:57:22">2020-11-25</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Transformer/">Transformer</a></span></div><div class="content">Why Transformer?
Transformer 是Google Brain在2017年的《Attention Is All You Need》中提出的。
Transformer针对RNN的弱点进行重新设计，解决了RNN效率问题和传递中的缺陷等。RNN对sequence（序列）进行串行的处理，Transformer对sequence进行并行的处理。
What is Transformer?
The Transformer - model architecture:  它是基于Encoder-Decoder结构的模型，在Encoder和Decoder中各有N个不同的Transformer block。
Positional Encoding
在Transformer中没有RNN的迭代操作（前一输出成为当下的输入），sequence中所有的word都被同等对待，所以word之间没有了先后关系，因此，Transformer架构中提出了Positional Encoding方案，给每个输入的词向量叠加一个固定的位置向量来区分位置关系。

位置编码需要满足以下准则：参考  ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2020/11/25/BERT/" title="NLP预训练模型之BERT">NLP预训练模型之BERT</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-25T02:47:46.000Z" title="Created 2020-11-25 10:47:46">2020-11-25</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/BERT/">BERT</a></span></div><div class="content">BERT
传统的word2vec
对于word2vec来说，一个词的词向量一旦训练好了之后就不变了(静态词向量)，但是在实际生活中一个词可能有不同的含义，所以word2vec不适用于多语意。
Transformer
BERT是基于Transformer架构的模型，首先来看Transformer。(我的另一篇单独Transformer博客)
BERT
BERT全称：Bidirectional Encoder Representations from Transformers
BERT == Transformer的Encoder部分
BERT论文
由于"Learn from a large amount of text without annotation"，BERT可以好好利用大量产生的无标注的数据,而Transformer需要有标注的数据。
向BERT中输入一个sequence，BERT输出sequence中word的Embedding。

如果进行没有标注的无监督训练，那BERT是如何训练的呢？

Approach 1：Masked Language M ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2020/11/24/pandas/" title="Pandas">Pandas</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-24T06:43:45.000Z" title="Created 2020-11-24 14:43:45">2020-11-24</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/python/">python</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Pandas/">Pandas</a></span></div><div class="content">Pandas
1 Pandas的数据类型
pandas中有两种数据类型：DateFrame和Series。
1.1 Series
Series是一种类似于一维数组的对象，是由一组数据以及一组与之相关联的标签（即索引）组成的，具体的表现形式就是索引在左边，值在右边。


创建Series


直接通过列表创建(索引的值是默认的自动创建一个0到N-1的整数索引)： 1s1 = pd.Series([4,7,-5,3]) 创建Series并且为其设置索引： 1s2 = pd.Series([4,7,-5,3], index=[&#x27;d&#x27;,&#x27;b&#x27;,&#x27;a&#x27;,&#x27;c&#x27;]) 通过字典创建Series————传入一个字典，则结果Series中的索引就是原字典的键，而且是按键有序排列： 12sdata = &#123;&#x27;Ohio&#x27;:35000,&#x27;Texas&#x27;:71000,&#x27;Oregon&#x27;:16000,&#x27;Utah&#x27;:5000&#125 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2020/11/22/%E5%A4%A9%E6%B1%A0%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90task0/" title="天池-新闻推荐之赛题理解+Baseline">天池-新闻推荐之赛题理解+Baseline</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-22T13:19:34.000Z" title="Created 2020-11-22 21:19:34">2020-11-22</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a></span></div><div class="content">赛题

新闻推荐比赛链接

赛题任务
赛题以预测用户未来点击新闻文章为任务，数据集报名后可见并可下载，该数据来自某新闻APP平台的用户交互数据，包括30万用户，近300万次点击，共36万多篇不同的新闻文章，同时每篇新闻文章有对应的embedding向量表示。为了保证比赛的公平性，将会从中抽取20万用户的点击日志数据作为训练集，5万用户的点击日志数据作为测试集A，5万用户的点击日志数据作为测试集B。
数据表
train_click_log.csv：训练集用户点击日志
testA_click_log.csv：测试集用户点击日志
articles.csv：新闻文章信息数据表
articles_emb.csv：新闻文章embedding向量表示
sample_submit.csv：提交样例文件
字段表



Field
Description




user_id
用户id


click_article_id
点击文章id


click_timestamp
点击时间戳


click_environment
点击环境 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2020/11/22/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B/" title="推荐系统简介">推荐系统简介</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-22T02:48:36.000Z" title="Created 2020-11-22 10:48:36">2020-11-22</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B/">推荐系统简介</a></span></div><div class="content">推荐系统简介
推荐系统的目的

让用户更快更好地获取到自己需要的内容。(在无数的商品信息中高效地获取到自己想要的物品)
让内容更好更快的推送到喜欢它的用户手中。
让平台更有效地保留用户资源。(用户在获取内容时的便利和优质资源的获得)

推荐系统的应用
推荐系统广泛应用在个性化音乐、电子商务、电影视频、社交网络、个性化阅读、位置服务、个性化邮件、个性化广告、个性化旅游、证券理财等。

个性化推荐是基于用字自己的数据生成的。热门推荐是基于大量的用户数据生成的。

推荐系统的基本思想

1 利用用户和物品的特征，给用户推荐那些具有用户喜欢特征的物品。(很多时候不知道用户喜欢的特征)
2 根据用户喜欢过的物品进行相似物品的推荐。(物以类聚)
3 根据与用户具有相似兴趣的用户所喜欢的物品进行推荐。(人以群分)

推荐系统的数据分析
用户信息
用户信息数据包含:

个人信息。例如性别、年龄等。
喜好标签。很多应用会让用户选择自己感兴趣的领域或者内容，利用这样的喜好标签进行内容的推荐。
上下文信息。如果没有个人信息和喜好标签，可以通过像获取浏览器的搜索 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2020/11/19/nltk/" title="自然语言处理库——NLTK">自然语言处理库——NLTK</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-19T12:51:35.000Z" title="Created 2020-11-19 20:51:35">2020-11-19</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/NLTK/">NLTK</a></span></div><div class="content">NLTK
NLTK介绍
NLTK(Natural Language Toolkit)是Python上著名的自然语言处理库，它自带语料库、词性分类库，还自带分词(tokenize)、分类等等功能。
NLTK有强大的社区(community)支持。
NLTK安装
Linux安装nltk命令： $pip install -U nltk

-U参数是指update(更新)。

测试是否安装成功： 在终端窗口： 12$ python&gt;&gt;&gt; import nltk ## NLTK的使用
安装语料库
12import nltknltk.download()
下载时可能会出现[error connecting to sever]，就是出现连接失败的情况，原因是nltk语料库的服务器需要连外网才能访问，所以修改下DNS地址。

Linux修改DNS地址： sudo vim /etc/resolv.conf,将文件中的nameserver后的ip改为8.8.8.8

选择要下载的内容，这里我只下载了nltk的book。  下载到的路径可以自己更改。
NL ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2020/11/18/HowToSolve/" title="0 如何解决一个问题?">0 如何解决一个问题?</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-18T08:37:07.000Z" title="Created 2020-11-18 16:37:07">2020-11-18</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/">数据结构与算法</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98/">如何解决一个问题</a></span></div><div class="content">编程时，如何解决一个问题？
第一步 确保理解问题

一个问题是由可能的输入和输入与输出之间的关系所定义的。


首先 不要紧张
看清输入是什么，输入是如何表示的
看清输出是什么

解决问题

首先 自己手写一些例子的解决过程（从简单的例子开始），想象人会怎么解决
通过例子开始写算法的伪码，不需要关注细节，先将大致的想法写出来。
如果通过思考人的解决方式所得出的方法比较复杂，重新开始思考新的简单的方式，因为计算机适合重复和枯燥的计算，所以开始想最直接简单的方式（后面需要优化的时候再去优化）。

写伪码时，写的是重要且简单的步骤（步骤复杂的地方选择用函数来实现）

一步一步地写出伪码对应的程序，如果有必要每一步需要测试其正确与否。


</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2020/11/18/nlp%E4%BB%BB%E5%8A%A1/" title="NLP的任务">NLP的任务</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-18T04:36:54.000Z" title="Created 2020-11-18 12:36:54">2020-11-18</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/NLP%E7%9A%84%E4%BB%BB%E5%8A%A1/">NLP的任务</a></span></div><div class="content">NLP根据任务不同，可以分为： token-level task:任务的目标是token级别。例如，Cloze(完形填空)是为了预测句子中某处的词，POS(词性标注)是为了确定文本中每个词的词性（包括动词、名词等等），NER(命名实体识别）是为了从文本中识别出命名实体（实体包括人名、地名等等），以及其他。 sequence-level task:任务的目标是句子级别。例如，NLI(自然语言推理)是为了判断两个句子之间的关系（相近？矛盾？还是中立？）。
token-level task
1. NER (Named Entity Recognition)
命名实体识别任务，从文本中识别出命名实体，实体一般包括人名、地名、机构名、时间等，还有更加专业的专业实体。 NER的本质是对句子中的每个token打标签, 判断每个token的类别。
常用的数据集有:

NER (Named Entity Recognition) dataset: 实体包含Person, Organization, Location, Miscellaneous, or Other (non-named en ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2020/11/18/NLP%E5%9F%BA%E7%A1%80%E4%B9%8B%E8%AF%8D%E5%90%91%E9%87%8F/" title="NLP基础之词向量">NLP基础之词向量</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-18T03:54:12.000Z" title="Created 2020-11-18 11:54:12">2020-11-18</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E8%AF%8D%E5%90%91%E9%87%8F/">词向量</a></span></div><div class="content">词(Word)
对于人类所理解的词语，英文单词（比如apple）为一个词，中文里一个字（中）或者一个词语（苹果）为一个词。
1 词向量(Word Vector)
1.1 词向量简介
词向量也叫做词嵌入(Word Embedding)，将人类所理解的自然语言的词映射为实数向量，也就是将文本中的词转换为数字向量的方法。一般情况下是将一个单词用高维的向量来表示，例如：
"狗"表示为[2, 3, 3]
"猫"表示为[1, 2, 3]
"雪"表示为[14, 2, 1]
1.2 词向量相似性度量
对于上述三个词向量，常见的方法是使用余弦相似度来计算词向量之间的距离：
狗和猫的余弦相似度： \[
cos(\theta_1) = \frac{2\times1+3\times2+3\times3}{\sqrt{2\times2+3\times3+3\times3}\sqrt{1\times1+2\times2+3\times3}} = 0.969
\]
狗和雪的余弦相似度为： \[
cos(\theta_2) = \frac{2\times14+3\times2+3\time ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/8/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><span class="page-number current">9</span></div></nav></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/cosmos.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">李子梅</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">89</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">108</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">9</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/LZMcosmos"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/LZMcosmos" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:609792588@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">“莱布尼茨在他的二进位算术中看到了宇宙创始的原像。他想象1表示上帝，而0表示虚无，上帝从虚无中创造出所有实物，恰如在他的数学系统中用1和0表示了所有的数。”</div></div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/03/13/Mysql%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" title="MySQL环境搭建">MySQL环境搭建</a><time datetime="2022-03-13T01:08:47.000Z" title="Created 2022-03-13 09:08:47">2022-03-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/11/01/CRF/" title="条件随机场（CRF）">条件随机场（CRF）</a><time datetime="2021-11-01T03:28:44.000Z" title="Created 2021-11-01 11:28:44">2021-11-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/07/14/%E5%AD%97%E7%AC%A6%E4%B8%B2/" title="字符串">字符串</a><time datetime="2021-07-13T16:30:25.000Z" title="Created 2021-07-14 00:30:25">2021-07-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/06/29/Heap/" title="堆">堆</a><time datetime="2021-06-29T04:45:04.000Z" title="Created 2021-06-29 12:45:04">2021-06-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/05/14/Stacking-of-Steam/" title="Stacking集成学习案例二：蒸汽量预测">Stacking集成学习案例二：蒸汽量预测</a><time datetime="2021-05-14T03:50:07.000Z" title="Created 2021-05-14 11:50:07">2021-05-14</time></div></div></div></div></div><div class="card-widget card-categories"><div class="card-content"><div class="item-headline"><i class="fas fa-folder-open"></i><span>Categories</span></div><ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/NLP/"><span class="card-category-list-name">NLP</span><span class="card-category-list-count">27</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/SQL/"><span class="card-category-list-name">SQL</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/hexo%E5%86%99%E5%8D%9A%E5%AE%A2/"><span class="card-category-list-name">hexo写博客</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/python/"><span class="card-category-list-name">python</span><span class="card-category-list-count">6</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"><span class="card-category-list-name">推荐系统</span><span class="card-category-list-count">6</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="card-category-list-name">数据结构与算法</span><span class="card-category-list-count">28</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="card-category-list-name">机器学习</span><span class="card-category-list-count">16</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E7%BC%96%E7%A8%8B/"><span class="card-category-list-name">编程</span><span class="card-category-list-count">2</span></a></li>
            <li class="card-category-list-item more is-center"><a class="card-category-list-link-more" href="/categories/">
                <span>More</span><i class="fas fa-angle-right"></i></a></li>
            </ul></div></div><div class="card-widget card-tags"><div class="card-content"><div class="item-headline"><i class="fas fa-tags"></i><span>Tags</span></div><div class="card-tag-cloud"><a href="/tags/AC%E8%87%AA%E5%8A%A8%E6%9C%BA-AC-Tree/" style="font-size: 1.1em; color: #999">AC自动机(AC Tree)</a> <a href="/tags/Adaboost/" style="font-size: 1.1em; color: #999">Adaboost</a> <a href="/tags/Albert%E5%AE%9E%E6%88%98%E4%B9%8BSentence-pair-classification/" style="font-size: 1.1em; color: #999">Albert实战之Sentence pair classification</a> <a href="/tags/B-%E6%A0%91/" style="font-size: 1.1em; color: #999">B+树</a> <a href="/tags/BERT/" style="font-size: 1.1em; color: #999">BERT</a> <a href="/tags/Bagging/" style="font-size: 1.1em; color: #999">Bagging</a> <a href="/tags/Blending/" style="font-size: 1.1em; color: #999">Blending</a> <a href="/tags/Boosting/" style="font-size: 1.1em; color: #999">Boosting</a> <a href="/tags/B%E6%A0%91/" style="font-size: 1.1em; color: #999">B树</a> <a href="/tags/ConvLab%E4%BD%BF%E7%94%A8/" style="font-size: 1.1em; color: #999">ConvLab使用</a> <a href="/tags/DFS%E4%B8%8EBFS/" style="font-size: 1.1em; color: #999">DFS与BFS</a> <a href="/tags/Few-shot-Learning/" style="font-size: 1.1em; color: #999">Few-shot Learning</a> <a href="/tags/GBDT/" style="font-size: 1.1em; color: #999">GBDT</a> <a href="/tags/Glyph-vector/" style="font-size: 1.1em; color: #999">Glyph-vector</a> <a href="/tags/KL%E6%95%A3%E5%BA%A6/" style="font-size: 1.1em; color: #999">KL散度</a> <a href="/tags/LRU-%E6%9C%80%E8%BF%91%E6%9C%80%E5%B0%91%E4%BD%BF%E7%94%A8%E7%AE%97%E6%B3%95/" style="font-size: 1.1em; color: #999">LRU(最近最少使用算法)</a> <a href="/tags/Latex%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/" style="font-size: 1.1em; color: #999">Latex数学公式</a> <a href="/tags/LightGBM/" style="font-size: 1.1em; color: #999">LightGBM</a> <a href="/tags/Mysql%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" style="font-size: 1.1em; color: #999">Mysql环境搭建</a> <a href="/tags/NLP%E4%B8%8E%E5%B8%B8%E8%A7%81%E5%9F%BA%E7%A1%80%E4%BB%BB%E5%8A%A1%E3%80%81%E5%BA%94%E7%94%A8/" style="font-size: 1.1em; color: #999">NLP与常见基础任务、应用</a> <a href="/tags/NLP%E7%9A%84%E4%BB%BB%E5%8A%A1/" style="font-size: 1.1em; color: #999">NLP的任务</a> <a href="/tags/NLTK/" style="font-size: 1.1em; color: #999">NLTK</a> <a href="/tags/Neo4J/" style="font-size: 1.5em; color: #99a9bf">Neo4J</a> <a href="/tags/Numpy%E4%B8%8E%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/" style="font-size: 1.1em; color: #999">Numpy与线性代数</a> <a href="/tags/PCA%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%AE%9E%E6%88%98/" style="font-size: 1.1em; color: #999">PCA简介与实战</a> <a href="/tags/Pandas/" style="font-size: 1.1em; color: #999">Pandas</a> <a href="/tags/Stacking/" style="font-size: 1.1em; color: #999">Stacking</a> <a href="/tags/Stacking%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%A1%88%E4%BE%8B%E4%B8%80/" style="font-size: 1.1em; color: #999">Stacking集成学习案例一</a> <a href="/tags/Stacking%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%A1%88%E4%BE%8B%E4%BA%8C/" style="font-size: 1.1em; color: #999">Stacking集成学习案例二</a> <a href="/tags/Transformer/" style="font-size: 1.1em; color: #999">Transformer</a> <a href="/tags/Trie/" style="font-size: 1.1em; color: #999">Trie</a> <a href="/tags/VSCode%E4%B8%8A%E9%9D%A2%E8%BF%9B%E8%A1%8CLeetcode%E7%BC%96%E7%A8%8B/" style="font-size: 1.1em; color: #999">VSCode上面进行Leetcode编程</a> <a href="/tags/XGBoost/" style="font-size: 1.1em; color: #999">XGBoost</a> <a href="/tags/cache-%E7%BC%93%E5%AD%98/" style="font-size: 1.1em; color: #999">cache(缓存)</a> <a href="/tags/hexo%E5%8D%9A%E5%AE%A2%E6%B8%B2%E6%9F%93%E5%99%A8-pandoc/" style="font-size: 1.1em; color: #999">hexo博客渲染器--pandoc</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/" style="font-size: 1.1em; color: #999">二分查找</a> <a href="/tags/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/" style="font-size: 1.1em; color: #999">二叉搜索树</a> <a href="/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/" style="font-size: 1.1em; color: #999">二叉树</a> <a href="/tags/%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83/" style="font-size: 1.1em; color: #999">二项分布</a> <a href="/tags/%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/" style="font-size: 1.1em; color: #999">优化方法</a></div></div></div><div class="card-widget card-archives"><div class="card-content"><div class="item-headline"><i class="fas fa-archive"></i><span>Archives</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/03/"><span class="card-archive-list-date">March 2022</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/11/"><span class="card-archive-list-date">November 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/07/"><span class="card-archive-list-date">July 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/06/"><span class="card-archive-list-date">June 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/05/"><span class="card-archive-list-date">May 2021</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/04/"><span class="card-archive-list-date">April 2021</span><span class="card-archive-list-count">12</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/03/"><span class="card-archive-list-date">March 2021</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/02/"><span class="card-archive-list-date">February 2021</span><span class="card-archive-list-count">11</span></a></li><li class="card-archive-list-item more is-center"><a class="card-archive-list-link-more" href="/archives/">
              <span>More</span><i class="fas fa-angle-right"  ></i></a></li></ul></div></div><div class="card-widget card-webinfo"><div class="card-content"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article :</div><div class="item-count">89</div></div><div class="webinfo-item"><div class="item-name">UV :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">PV :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">Last Push :</div><div class="item-count" id="last-push-date" data-lastPushDate="2022-03-14T01:54:44.064Z"></div></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(/img/Green_Planet_Space_Satellite_Universe.jpg)"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By 李子梅</div><div class="footer_custom_text">welcome to my <a href="https://lzmcosmos.github.io/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    var typed = new Typed("#subtitle", {
      strings: "活着的每一瞬间都是存在的意义,你一定能够成为你想要去成为的人,Never put off till tomorrow what you can do today".split(","),
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("subtitle").innerHTML = '活着的每一瞬间都是存在的意义'
  }
}

if (true) {
  if (typeof Typed === 'function') subtitleType()
  else $.getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js', subtitleType)
} else {
  subtitleType()
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script>(function(){
  const bp = document.createElement('script');
  const curProtocol = window.location.protocol.split(':')[0];
  if (curProtocol === 'https'){
  bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
  }
  else{
  bp.src = 'http://push.zhanzhang.baidu.com/push.js';
  }
  bp.dataset.pjax = ''
  const s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(bp, s);
})()</script></div></body></html>