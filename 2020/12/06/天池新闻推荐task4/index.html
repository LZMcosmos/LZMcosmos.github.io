<!DOCTYPE html><html lang="zn-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>天池-新闻推荐之排序模型与模型融合 | LZMcosmos</title><meta name="author" content="李子梅"><meta name="copyright" content="李子梅"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="排序模型 在推荐系统中，召回之后就是对召回后的候选集进行排序。 通过召回的操作进行了问题规模的缩减，对于每个用户选择出了N篇文章作为候选集，并基于召回的候选集构建了与用户历史相关的特征，以及用户本身的属性、文章本身的属性特征、用户与文章之间的特征。 排序阶段可以使用机器学习的方法:通过机器学习模型对构造好的特征进行学习，然后对测试集进行预测，得到测试集中每个候选集用户点击的概率，返回点击概率">
<meta property="og:type" content="article">
<meta property="og:title" content="天池-新闻推荐之排序模型与模型融合">
<meta property="og:url" content="https://lzmcosmos.github.io/2020/12/06/%E5%A4%A9%E6%B1%A0%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90task4/index.html">
<meta property="og:site_name" content="LZMcosmos">
<meta property="og:description" content="排序模型 在推荐系统中，召回之后就是对召回后的候选集进行排序。 通过召回的操作进行了问题规模的缩减，对于每个用户选择出了N篇文章作为候选集，并基于召回的候选集构建了与用户历史相关的特征，以及用户本身的属性、文章本身的属性特征、用户与文章之间的特征。 排序阶段可以使用机器学习的方法:通过机器学习模型对构造好的特征进行学习，然后对测试集进行预测，得到测试集中每个候选集用户点击的概率，返回点击概率">
<meta property="og:locale" content="zn_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg">
<meta property="article:published_time" content="2020-12-06T13:09:38.000Z">
<meta property="article:modified_time" content="2021-03-19T05:34:26.647Z">
<meta property="article:author" content="李子梅">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><link rel="shortcut icon" href="/img/cosmos.jpg"><link rel="canonical" href="https://lzmcosmos.github.io/2020/12/06/%E5%A4%A9%E6%B1%A0%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90task4/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="preconnect" href="//zz.bdstatic.com"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-03-19 13:34:26'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><meta name="generator" content="Hexo 5.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/cosmos.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">89</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">108</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">9</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/Nebula_planets-Universe.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">LZMcosmos</a></span><span id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><h1 class="post-title">天池-新闻推荐之排序模型与模型融合</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-12-06T13:09:38.000Z" title="Created 2020-12-06 21:09:38">2020-12-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2021-03-19T05:34:26.647Z" title="Updated 2021-03-19 13:34:26">2021-03-19</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="排序模型">排序模型</h1>
<p>在推荐系统中，召回之后就是对召回后的候选集进行排序。</p>
<p>通过召回的操作进行了问题规模的缩减，对于每个用户选择出了N篇文章作为候选集，并基于召回的候选集构建了与用户历史相关的特征，以及用户本身的属性、文章本身的属性特征、用户与文章之间的特征。</p>
<p>排序阶段可以使用机器学习的方法:通过机器学习模型对构造好的特征进行学习，然后对测试集进行预测，得到测试集中每个候选集用户点击的概率，返回点击概率最大的Topk个文章作为最终的结果。</p>
<h2 id="排序模型的选择">排序模型的选择</h2>
<p>排序阶段选择了三个比较有代表性的排序模型，它们分别是:</p>
<ul>
<li><p>LGB排序模型</p></li>
<li><p>LGB分类模型</p></li>
<li><p>深度学习的分类模型DIN</p></li>
</ul>
<p>排序模型们的结果出来后，使用模型集成的方法选择出较好的结果。</p>
<h2 id="经典的模型集成方法">经典的模型集成方法</h2>
<ul>
<li>输出结果的<strong>加权融合</strong></li>
<li><strong>Stacking</strong>(将模型的输出结果在使用一个简单模型进行预测)</li>
</ul>
<h2 id="导入包">导入包</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> gc, os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="读取排序特征">读取排序特征</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data_path = <span class="string">&#x27;./raw_data/&#x27;</span></span><br><span class="line">save_path = <span class="string">&#x27;./temp_results/&#x27;</span></span><br><span class="line">offline = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重新读取数据的时候，发现click_article_id是一个浮点数，所以将其转换成int类型</span></span><br><span class="line">trn_user_item_feats_df = pd.read_csv(save_path + <span class="string">&#x27;trn_user_item_feats_df.csv&#x27;</span>)</span><br><span class="line">trn_user_item_feats_df[<span class="string">&#x27;click_article_id&#x27;</span>] = trn_user_item_feats_df[<span class="string">&#x27;click_article_id&#x27;</span>].astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> offline:</span><br><span class="line">    val_user_item_feats_df = pd.read_csv(save_path + <span class="string">&#x27;val_user_item_feats_df.csv&#x27;</span>)</span><br><span class="line">    val_user_item_feats_df[<span class="string">&#x27;click_article_id&#x27;</span>] = val_user_item_feats_df[<span class="string">&#x27;click_article_id&#x27;</span>].astype(<span class="built_in">int</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    val_user_item_feats_df = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">tst_user_item_feats_df = pd.read_csv(save_path + <span class="string">&#x27;tst_user_item_feats_df.csv&#x27;</span>)</span><br><span class="line">tst_user_item_feats_df[<span class="string">&#x27;click_article_id&#x27;</span>] = tst_user_item_feats_df[<span class="string">&#x27;click_article_id&#x27;</span>].astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 做特征的时候为了方便，给测试集也打上了一个无效的标签，这里直接删掉就行</span></span><br><span class="line"><span class="keyword">del</span> tst_user_item_feats_df[<span class="string">&#x27;label&#x27;</span>]</span><br></pre></td></tr></table></figure>
<h2 id="返回排序后的结果">返回排序后的结果</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">submit</span>(<span class="params">recall_df, topk=<span class="number">5</span>, model_name=<span class="literal">None</span></span>):</span></span><br><span class="line">    recall_df = recall_df.sort_values(by=[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>])</span><br><span class="line">    recall_df[<span class="string">&#x27;rank&#x27;</span>] = recall_df.groupby([<span class="string">&#x27;user_id&#x27;</span>])[<span class="string">&#x27;pred_score&#x27;</span>].rank(ascending=<span class="literal">False</span>, method=<span class="string">&#x27;first&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 判断是不是每个用户都有5篇文章及以上</span></span><br><span class="line">    tmp = recall_df.groupby(<span class="string">&#x27;user_id&#x27;</span>).apply(<span class="keyword">lambda</span> x: x[<span class="string">&#x27;rank&#x27;</span>].<span class="built_in">max</span>())</span><br><span class="line">    <span class="keyword">assert</span> tmp.<span class="built_in">min</span>() &gt;= topk</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">del</span> recall_df[<span class="string">&#x27;pred_score&#x27;</span>]</span><br><span class="line">    submit = recall_df[recall_df[<span class="string">&#x27;rank&#x27;</span>] &lt;= topk].set_index([<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;rank&#x27;</span>]).unstack(-<span class="number">1</span>).reset_index()</span><br><span class="line">    </span><br><span class="line">    submit.columns = [<span class="built_in">int</span>(col) <span class="keyword">if</span> <span class="built_in">isinstance</span>(col, <span class="built_in">int</span>) <span class="keyword">else</span> col <span class="keyword">for</span> col <span class="keyword">in</span> submit.columns.droplevel(<span class="number">0</span>)]</span><br><span class="line">    <span class="comment"># 按照提交格式定义列名</span></span><br><span class="line">    submit = submit.rename(columns=&#123;<span class="string">&#x27;&#x27;</span>: <span class="string">&#x27;user_id&#x27;</span>, <span class="number">1</span>: <span class="string">&#x27;article_1&#x27;</span>, <span class="number">2</span>: <span class="string">&#x27;article_2&#x27;</span>, </span><br><span class="line">                                                  <span class="number">3</span>: <span class="string">&#x27;article_3&#x27;</span>, <span class="number">4</span>: <span class="string">&#x27;article_4&#x27;</span>, <span class="number">5</span>: <span class="string">&#x27;article_5&#x27;</span>&#125;)</span><br><span class="line">    </span><br><span class="line">    save_name = save_path + model_name + <span class="string">&#x27;_&#x27;</span> + datetime.today().strftime(<span class="string">&#x27;%m-%d&#x27;</span>) + <span class="string">&#x27;.csv&#x27;</span></span><br><span class="line">    submit.to_csv(save_name, index=<span class="literal">False</span>, header=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 排序结果归一化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">norm_sim</span>(<span class="params">sim_df, weight=<span class="number">0.0</span></span>):</span></span><br><span class="line">    <span class="comment"># print(sim_df.head())</span></span><br><span class="line">    min_sim = sim_df.<span class="built_in">min</span>()</span><br><span class="line">    max_sim = sim_df.<span class="built_in">max</span>()</span><br><span class="line">    <span class="keyword">if</span> max_sim == min_sim:</span><br><span class="line">        sim_df = sim_df.apply(<span class="keyword">lambda</span> sim: <span class="number">1.0</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        sim_df = sim_df.apply(<span class="keyword">lambda</span> sim: <span class="number">1.0</span> * (sim - min_sim) / (max_sim - min_sim))</span><br><span class="line"></span><br><span class="line">    sim_df = sim_df.apply(<span class="keyword">lambda</span> sim: sim + weight)  <span class="comment"># plus one</span></span><br><span class="line">    <span class="keyword">return</span> sim_df</span><br></pre></td></tr></table></figure>
<h2 id="lgb排序模型">LGB排序模型</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 防止中间出错之后重新读取数据</span></span><br><span class="line">trn_user_item_feats_df_rank_model = trn_user_item_feats_df.copy()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> offline:</span><br><span class="line">    val_user_item_feats_df_rank_model = val_user_item_feats_df.copy()</span><br><span class="line">    </span><br><span class="line">tst_user_item_feats_df_rank_model = tst_user_item_feats_df.copy()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义特征列</span></span><br><span class="line">lgb_cols = [<span class="string">&#x27;sim0&#x27;</span>, <span class="string">&#x27;time_diff0&#x27;</span>, <span class="string">&#x27;word_diff0&#x27;</span>,<span class="string">&#x27;sim_max&#x27;</span>, <span class="string">&#x27;sim_min&#x27;</span>, <span class="string">&#x27;sim_sum&#x27;</span>, </span><br><span class="line">            <span class="string">&#x27;sim_mean&#x27;</span>, <span class="string">&#x27;score&#x27;</span>,<span class="string">&#x27;click_size&#x27;</span>, <span class="string">&#x27;time_diff_mean&#x27;</span>, <span class="string">&#x27;active_level&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;click_environment&#x27;</span>,<span class="string">&#x27;click_deviceGroup&#x27;</span>, <span class="string">&#x27;click_os&#x27;</span>, <span class="string">&#x27;click_country&#x27;</span>, </span><br><span class="line">            <span class="string">&#x27;click_region&#x27;</span>,<span class="string">&#x27;click_referrer_type&#x27;</span>, <span class="string">&#x27;user_time_hob1&#x27;</span>, <span class="string">&#x27;user_time_hob2&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;words_hbo&#x27;</span>, <span class="string">&#x27;category_id&#x27;</span>, <span class="string">&#x27;created_at_ts&#x27;</span>,<span class="string">&#x27;words_count&#x27;</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 排序模型分组</span></span><br><span class="line">trn_user_item_feats_df_rank_model.sort_values(by=[<span class="string">&#x27;user_id&#x27;</span>], inplace=<span class="literal">True</span>)</span><br><span class="line">g_train = trn_user_item_feats_df_rank_model.groupby([<span class="string">&#x27;user_id&#x27;</span>], as_index=<span class="literal">False</span>).count()[<span class="string">&quot;label&quot;</span>].values</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> offline:</span><br><span class="line">    val_user_item_feats_df_rank_model.sort_values(by=[<span class="string">&#x27;user_id&#x27;</span>], inplace=<span class="literal">True</span>)</span><br><span class="line">    g_val = val_user_item_feats_df_rank_model.groupby([<span class="string">&#x27;user_id&#x27;</span>], as_index=<span class="literal">False</span>).count()[<span class="string">&quot;label&quot;</span>].values</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 排序模型定义</span></span><br><span class="line">lgb_ranker = lgb.LGBMRanker(boosting_type=<span class="string">&#x27;gbdt&#x27;</span>, num_leaves=<span class="number">31</span>, reg_alpha=<span class="number">0.0</span>, reg_lambda=<span class="number">1</span>,</span><br><span class="line">                            max_depth=-<span class="number">1</span>, n_estimators=<span class="number">100</span>, subsample=<span class="number">0.7</span>, colsample_bytree=<span class="number">0.7</span>, subsample_freq=<span class="number">1</span>,</span><br><span class="line">                            learning_rate=<span class="number">0.01</span>, min_child_weight=<span class="number">50</span>, random_state=<span class="number">2018</span>, n_jobs= <span class="number">16</span>)  </span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 排序模型训练</span></span><br><span class="line"><span class="keyword">if</span> offline:</span><br><span class="line">    lgb_ranker.fit(trn_user_item_feats_df_rank_model[lgb_cols], trn_user_item_feats_df_rank_model[<span class="string">&#x27;label&#x27;</span>], group=g_train,</span><br><span class="line">                eval_set=[(val_user_item_feats_df_rank_model[lgb_cols], val_user_item_feats_df_rank_model[<span class="string">&#x27;label&#x27;</span>])], </span><br><span class="line">                eval_group= [g_val], eval_at=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], eval_metric=[<span class="string">&#x27;ndcg&#x27;</span>, ], early_stopping_rounds=<span class="number">50</span>, )</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    lgb_ranker.fit(trn_user_item_feats_df[lgb_cols], trn_user_item_feats_df[<span class="string">&#x27;label&#x27;</span>], group=g_train)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">tst_user_item_feats_df[<span class="string">&#x27;pred_score&#x27;</span>] = lgb_ranker.predict(tst_user_item_feats_df[lgb_cols], num_iteration=lgb_ranker.best_iteration_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将这里的排序结果保存一份，用户后面的模型融合</span></span><br><span class="line">tst_user_item_feats_df[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>]].to_csv(save_path + <span class="string">&#x27;lgb_ranker_score.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测结果重新排序, 及生成提交结果</span></span><br><span class="line">rank_results = tst_user_item_feats_df[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>]]</span><br><span class="line">rank_results[<span class="string">&#x27;click_article_id&#x27;</span>] = rank_results[<span class="string">&#x27;click_article_id&#x27;</span>].astype(<span class="built_in">int</span>)</span><br><span class="line">submit(rank_results, topk=<span class="number">5</span>, model_name=<span class="string">&#x27;lgb_ranker&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 五折交叉验证，这里的五折交叉是以用户为目标进行五折划分</span></span><br><span class="line"><span class="comment">#  这一部分与前面的单独训练和验证是分开的</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_kfold_users</span>(<span class="params">trn_df, n=<span class="number">5</span></span>):</span></span><br><span class="line">    user_ids = trn_df[<span class="string">&#x27;user_id&#x27;</span>].unique()</span><br><span class="line">    user_set = [user_ids[i::n] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    <span class="keyword">return</span> user_set</span><br><span class="line"></span><br><span class="line">k_fold = <span class="number">5</span></span><br><span class="line">trn_df = trn_user_item_feats_df_rank_model</span><br><span class="line">user_set = get_kfold_users(trn_df, n=k_fold)</span><br><span class="line"></span><br><span class="line">score_list = []</span><br><span class="line">score_df = trn_df[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>,<span class="string">&#x27;label&#x27;</span>]]</span><br><span class="line">sub_preds = np.zeros(tst_user_item_feats_df_rank_model.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 五折交叉验证，并将中间结果保存用于staking</span></span><br><span class="line"><span class="keyword">for</span> n_fold, valid_user <span class="keyword">in</span> <span class="built_in">enumerate</span>(user_set):</span><br><span class="line">    train_idx = trn_df[~trn_df[<span class="string">&#x27;user_id&#x27;</span>].isin(valid_user)] <span class="comment"># add slide user</span></span><br><span class="line">    valid_idx = trn_df[trn_df[<span class="string">&#x27;user_id&#x27;</span>].isin(valid_user)]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 训练集与验证集的用户分组</span></span><br><span class="line">    train_idx.sort_values(by=[<span class="string">&#x27;user_id&#x27;</span>], inplace=<span class="literal">True</span>)</span><br><span class="line">    g_train = train_idx.groupby([<span class="string">&#x27;user_id&#x27;</span>], as_index=<span class="literal">False</span>).count()[<span class="string">&quot;label&quot;</span>].values</span><br><span class="line">    </span><br><span class="line">    valid_idx.sort_values(by=[<span class="string">&#x27;user_id&#x27;</span>], inplace=<span class="literal">True</span>)</span><br><span class="line">    g_val = valid_idx.groupby([<span class="string">&#x27;user_id&#x27;</span>], as_index=<span class="literal">False</span>).count()[<span class="string">&quot;label&quot;</span>].values</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 定义模型</span></span><br><span class="line">    lgb_ranker = lgb.LGBMRanker(boosting_type=<span class="string">&#x27;gbdt&#x27;</span>, num_leaves=<span class="number">31</span>, reg_alpha=<span class="number">0.0</span>, reg_lambda=<span class="number">1</span>,</span><br><span class="line">                            max_depth=-<span class="number">1</span>, n_estimators=<span class="number">100</span>, subsample=<span class="number">0.7</span>, colsample_bytree=<span class="number">0.7</span>, subsample_freq=<span class="number">1</span>,</span><br><span class="line">                            learning_rate=<span class="number">0.01</span>, min_child_weight=<span class="number">50</span>, random_state=<span class="number">2018</span>, n_jobs= <span class="number">16</span>)  </span><br><span class="line">    <span class="comment"># 训练模型</span></span><br><span class="line">    lgb_ranker.fit(train_idx[lgb_cols], train_idx[<span class="string">&#x27;label&#x27;</span>], group=g_train,</span><br><span class="line">                   eval_set=[(valid_idx[lgb_cols], valid_idx[<span class="string">&#x27;label&#x27;</span>])], eval_group= [g_val], </span><br><span class="line">                   eval_at=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], eval_metric=[<span class="string">&#x27;ndcg&#x27;</span>, ], early_stopping_rounds=<span class="number">50</span>, )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 预测验证集结果</span></span><br><span class="line">    valid_idx[<span class="string">&#x27;pred_score&#x27;</span>] = lgb_ranker.predict(valid_idx[lgb_cols], num_iteration=lgb_ranker.best_iteration_)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 对输出结果进行归一化</span></span><br><span class="line">    valid_idx[<span class="string">&#x27;pred_score&#x27;</span>] = valid_idx[[<span class="string">&#x27;pred_score&#x27;</span>]].transform(<span class="keyword">lambda</span> x: norm_sim(x))</span><br><span class="line">    </span><br><span class="line">    valid_idx.sort_values(by=[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>])</span><br><span class="line">    valid_idx[<span class="string">&#x27;pred_rank&#x27;</span>] = valid_idx.groupby([<span class="string">&#x27;user_id&#x27;</span>])[<span class="string">&#x27;pred_score&#x27;</span>].rank(ascending=<span class="literal">False</span>, method=<span class="string">&#x27;first&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将验证集的预测结果放到一个列表中，后面进行拼接</span></span><br><span class="line">    score_list.append(valid_idx[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>, <span class="string">&#x27;pred_rank&#x27;</span>]])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 如果是线上测试，需要计算每次交叉验证的结果相加，最后求平均</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> offline:</span><br><span class="line">        sub_preds += lgb_ranker.predict(tst_user_item_feats_df_rank_model[lgb_cols], lgb_ranker.best_iteration_)</span><br><span class="line">    </span><br><span class="line">score_df_ = pd.concat(score_list, axis=<span class="number">0</span>)</span><br><span class="line">score_df = score_df.merge(score_df_, how=<span class="string">&#x27;left&#x27;</span>, on=[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>])</span><br><span class="line"><span class="comment"># 保存训练集交叉验证产生的新特征</span></span><br><span class="line">score_df[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>, <span class="string">&#x27;pred_rank&#x27;</span>, <span class="string">&#x27;label&#x27;</span>]].to_csv(save_path + <span class="string">&#x27;trn_lgb_ranker_feats.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 测试集的预测结果，多次交叉验证求平均,将预测的score和对应的rank特征保存，可以用于后面的staking，这里还可以构造其他更多的特征</span></span><br><span class="line">tst_user_item_feats_df_rank_model[<span class="string">&#x27;pred_score&#x27;</span>] = sub_preds / k_fold</span><br><span class="line">tst_user_item_feats_df_rank_model[<span class="string">&#x27;pred_score&#x27;</span>] = tst_user_item_feats_df_rank_model[<span class="string">&#x27;pred_score&#x27;</span>].transform(<span class="keyword">lambda</span> x: norm_sim(x))</span><br><span class="line">tst_user_item_feats_df_rank_model.sort_values(by=[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>])</span><br><span class="line">tst_user_item_feats_df_rank_model[<span class="string">&#x27;pred_rank&#x27;</span>] = tst_user_item_feats_df_rank_model.groupby([<span class="string">&#x27;user_id&#x27;</span>])[<span class="string">&#x27;pred_score&#x27;</span>].rank(ascending=<span class="literal">False</span>, method=<span class="string">&#x27;first&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存测试集交叉验证的新特征</span></span><br><span class="line">tst_user_item_feats_df_rank_model[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>, <span class="string">&#x27;pred_rank&#x27;</span>]].to_csv(save_path + <span class="string">&#x27;tst_lgb_ranker_feats.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[1] valid_0&#39;s ndcg@1: 0.999975  valid_0&#39;s ndcg@2: 0.999991  valid_0&#39;s ndcg@3: 0.999991  valid_0&#39;s ndcg@4: 0.999991  valid_0&#39;s ndcg@5: 0.999991
Training until validation scores don&#39;t improve for 50 rounds
[2] valid_0&#39;s ndcg@1: 0.999975  valid_0&#39;s ndcg@2: 0.999991  valid_0&#39;s ndcg@3: 0.999991  valid_0&#39;s ndcg@4: 0.999991  valid_0&#39;s ndcg@5: 0.999991
[3] valid_0&#39;s ndcg@1: 0.999975  valid_0&#39;s ndcg@2: 0.999991  valid_0&#39;s ndcg@3: 0.999991  valid_0&#39;s ndcg@4: 0.999991  valid_0&#39;s ndcg@5: 0.999991
[4] valid_0&#39;s ndcg@1: 0.999975  valid_0&#39;s ndcg@2: 0.999991  valid_0&#39;s ndcg@3: 0.999991  valid_0&#39;s ndcg@4: 0.999991  valid_0&#39;s ndcg@5: 0.999991
[5] valid_0&#39;s ndcg@1: 0.999975  valid_0&#39;s ndcg@2: 0.999991  valid_0&#39;s ndcg@3: 0.999991  valid_0&#39;s ndcg@4: 0.999991  valid_0&#39;s ndcg@5: 0.999991
[6] valid_0&#39;s ndcg@1: 0.999975  valid_0&#39;s ndcg@2: 0.999991  valid_0&#39;s ndcg@3: 0.999991  valid_0&#39;s ndcg@4: 0.999991  valid_0&#39;s ndcg@5: 0.999991
[7] valid_0&#39;s ndcg@1: 0.999975  valid_0&#39;s ndcg@2: 0.999991  valid_0&#39;s ndcg@3: 0.999991  valid_0&#39;s ndcg@4: 0.999991  valid_0&#39;s ndcg@5: 0.999991</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测结果重新排序, 及生成提交结果</span></span><br><span class="line"><span class="comment"># 单模型生成提交结果</span></span><br><span class="line">rank_results = tst_user_item_feats_df_rank_model[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>]]</span><br><span class="line">rank_results[<span class="string">&#x27;click_article_id&#x27;</span>] = rank_results[<span class="string">&#x27;click_article_id&#x27;</span>].astype(<span class="built_in">int</span>)</span><br><span class="line">submit(rank_results, topk=<span class="number">5</span>, model_name=<span class="string">&#x27;lgb_ranker&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="lgb分类模型">LGB分类模型</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型及参数的定义</span></span><br><span class="line">lgb_Classfication = lgb.LGBMClassifier(boosting_type=<span class="string">&#x27;gbdt&#x27;</span>, num_leaves=<span class="number">31</span>, reg_alpha=<span class="number">0.0</span>, reg_lambda=<span class="number">1</span>,</span><br><span class="line">                            max_depth=-<span class="number">1</span>, n_estimators=<span class="number">500</span>, subsample=<span class="number">0.7</span>, colsample_bytree=<span class="number">0.7</span>, subsample_freq=<span class="number">1</span>,</span><br><span class="line">                            learning_rate=<span class="number">0.01</span>, min_child_weight=<span class="number">50</span>, random_state=<span class="number">2018</span>, n_jobs= <span class="number">16</span>, verbose=<span class="number">10</span>)  </span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line"><span class="keyword">if</span> offline:</span><br><span class="line">    lgb_Classfication.fit(trn_user_item_feats_df_rank_model[lgb_cols], trn_user_item_feats_df_rank_model[<span class="string">&#x27;label&#x27;</span>],</span><br><span class="line">                    eval_set=[(val_user_item_feats_df_rank_model[lgb_cols], val_user_item_feats_df_rank_model[<span class="string">&#x27;label&#x27;</span>])], </span><br><span class="line">                    eval_metric=[<span class="string">&#x27;auc&#x27;</span>, ],early_stopping_rounds=<span class="number">50</span>, )</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    lgb_Classfication.fit(trn_user_item_feats_df_rank_model[lgb_cols], trn_user_item_feats_df_rank_model[<span class="string">&#x27;label&#x27;</span>])</span><br></pre></td></tr></table></figure>
<pre><code>[LightGBM] [Info] Number of positive: 3, number of negative: 224359
[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.042821
[LightGBM] [Debug] init for col-wise cost 0.000009 seconds, init for row-wise cost 0.027437 seconds
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003699 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Debug] Using Dense Multi-Val Bin
[LightGBM] [Info] Total Bins 4035
[LightGBM] [Info] Number of data points in the train set: 224362, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000013 -&gt; initscore=-11.222390
[LightGBM] [Info] Start training from score -11.222390
[LightGBM] [Debug] Re-bagging, using 157250 data to train
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">tst_user_item_feats_df[<span class="string">&#x27;pred_score&#x27;</span>] = lgb_Classfication.predict_proba(tst_user_item_feats_df[lgb_cols])[:,<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将这里的排序结果保存一份，用户后面的模型融合</span></span><br><span class="line">tst_user_item_feats_df[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>]].to_csv(save_path + <span class="string">&#x27;lgb_cls_score.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测结果重新排序, 及生成提交结果</span></span><br><span class="line">rank_results = tst_user_item_feats_df[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>]]</span><br><span class="line">rank_results[<span class="string">&#x27;click_article_id&#x27;</span>] = rank_results[<span class="string">&#x27;click_article_id&#x27;</span>].astype(<span class="built_in">int</span>)</span><br><span class="line">submit(rank_results, topk=<span class="number">5</span>, model_name=<span class="string">&#x27;lgb_cls&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 五折交叉验证，这里的五折交叉是以用户为目标进行五折划分</span></span><br><span class="line"><span class="comment">#  这一部分与前面的单独训练和验证是分开的</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_kfold_users</span>(<span class="params">trn_df, n=<span class="number">5</span></span>):</span></span><br><span class="line">    user_ids = trn_df[<span class="string">&#x27;user_id&#x27;</span>].unique()</span><br><span class="line">    user_set = [user_ids[i::n] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    <span class="keyword">return</span> user_set</span><br><span class="line"></span><br><span class="line">k_fold = <span class="number">5</span></span><br><span class="line">trn_df = trn_user_item_feats_df_rank_model</span><br><span class="line">user_set = get_kfold_users(trn_df, n=k_fold)</span><br><span class="line"></span><br><span class="line">score_list = []</span><br><span class="line">score_df = trn_df[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;label&#x27;</span>]]</span><br><span class="line">sub_preds = np.zeros(tst_user_item_feats_df_rank_model.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 五折交叉验证，并将中间结果保存用于staking</span></span><br><span class="line"><span class="keyword">for</span> n_fold, valid_user <span class="keyword">in</span> <span class="built_in">enumerate</span>(user_set):</span><br><span class="line">    train_idx = trn_df[~trn_df[<span class="string">&#x27;user_id&#x27;</span>].isin(valid_user)] <span class="comment"># add slide user</span></span><br><span class="line">    valid_idx = trn_df[trn_df[<span class="string">&#x27;user_id&#x27;</span>].isin(valid_user)]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 模型及参数的定义</span></span><br><span class="line">    lgb_Classfication = lgb.LGBMClassifier(boosting_type=<span class="string">&#x27;gbdt&#x27;</span>, num_leaves=<span class="number">31</span>, reg_alpha=<span class="number">0.0</span>, reg_lambda=<span class="number">1</span>,</span><br><span class="line">                            max_depth=-<span class="number">1</span>, n_estimators=<span class="number">100</span>, subsample=<span class="number">0.7</span>, colsample_bytree=<span class="number">0.7</span>, subsample_freq=<span class="number">1</span>,</span><br><span class="line">                            learning_rate=<span class="number">0.01</span>, min_child_weight=<span class="number">50</span>, random_state=<span class="number">2018</span>, n_jobs= <span class="number">16</span>, verbose=<span class="number">10</span>)  </span><br><span class="line">    <span class="comment"># 训练模型</span></span><br><span class="line">    lgb_Classfication.fit(train_idx[lgb_cols], train_idx[<span class="string">&#x27;label&#x27;</span>],eval_set=[(valid_idx[lgb_cols], valid_idx[<span class="string">&#x27;label&#x27;</span>])], </span><br><span class="line">                          eval_metric=[<span class="string">&#x27;auc&#x27;</span>, ],early_stopping_rounds=<span class="number">50</span>, )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 预测验证集结果</span></span><br><span class="line">    valid_idx[<span class="string">&#x27;pred_score&#x27;</span>] = lgb_Classfication.predict_proba(valid_idx[lgb_cols], </span><br><span class="line">                                                              num_iteration=lgb_Classfication.best_iteration_)[:,<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 对输出结果进行归一化 分类模型输出的值本身就是一个概率值不需要进行归一化</span></span><br><span class="line">    <span class="comment"># valid_idx[&#x27;pred_score&#x27;] = valid_idx[[&#x27;pred_score&#x27;]].transform(lambda x: norm_sim(x))</span></span><br><span class="line">    </span><br><span class="line">    valid_idx.sort_values(by=[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>])</span><br><span class="line">    valid_idx[<span class="string">&#x27;pred_rank&#x27;</span>] = valid_idx.groupby([<span class="string">&#x27;user_id&#x27;</span>])[<span class="string">&#x27;pred_score&#x27;</span>].rank(ascending=<span class="literal">False</span>, method=<span class="string">&#x27;first&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将验证集的预测结果放到一个列表中，后面进行拼接</span></span><br><span class="line">    score_list.append(valid_idx[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>, <span class="string">&#x27;pred_rank&#x27;</span>]])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 如果是线上测试，需要计算每次交叉验证的结果相加，最后求平均</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> offline:</span><br><span class="line">        sub_preds += lgb_Classfication.predict_proba(tst_user_item_feats_df_rank_model[lgb_cols], </span><br><span class="line">                                                     num_iteration=lgb_Classfication.best_iteration_)[:,<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">score_df_ = pd.concat(score_list, axis=<span class="number">0</span>)</span><br><span class="line">score_df = score_df.merge(score_df_, how=<span class="string">&#x27;left&#x27;</span>, on=[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>])</span><br><span class="line"><span class="comment"># 保存训练集交叉验证产生的新特征</span></span><br><span class="line">score_df[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>, <span class="string">&#x27;pred_rank&#x27;</span>, <span class="string">&#x27;label&#x27;</span>]].to_csv(save_path + <span class="string">&#x27;trn_lgb_cls_feats.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 测试集的预测结果，多次交叉验证求平均,将预测的score和对应的rank特征保存，可以用于后面的staking，这里还可以构造其他更多的特征</span></span><br><span class="line">tst_user_item_feats_df_rank_model[<span class="string">&#x27;pred_score&#x27;</span>] = sub_preds / k_fold</span><br><span class="line">tst_user_item_feats_df_rank_model[<span class="string">&#x27;pred_score&#x27;</span>] = tst_user_item_feats_df_rank_model[<span class="string">&#x27;pred_score&#x27;</span>].transform(<span class="keyword">lambda</span> x: norm_sim(x))</span><br><span class="line">tst_user_item_feats_df_rank_model.sort_values(by=[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>])</span><br><span class="line">tst_user_item_feats_df_rank_model[<span class="string">&#x27;pred_rank&#x27;</span>] = tst_user_item_feats_df_rank_model.groupby([<span class="string">&#x27;user_id&#x27;</span>])[<span class="string">&#x27;pred_score&#x27;</span>].rank(ascending=<span class="literal">False</span>, method=<span class="string">&#x27;first&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存测试集交叉验证的新特征</span></span><br><span class="line">tst_user_item_feats_df_rank_model[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>, <span class="string">&#x27;pred_rank&#x27;</span>]].to_csv(save_path + <span class="string">&#x27;tst_lgb_cls_feats.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[LightGBM] [Info] Number of positive: 2, number of negative: 179472
[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.042815
[LightGBM] [Debug] init for col-wise cost 0.000225 seconds, init for row-wise cost 0.005849 seconds
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007854 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4028
[LightGBM] [Info] Number of data points in the train set: 179474, number of used features: 23
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000011 -&gt; initscore=-11.404627
[LightGBM] [Info] Start training from score -11.404627
[LightGBM] [Debug] Re-bagging, using 125734 data to train
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[1] valid_0&#39;s auc: 0.5  valid_0&#39;s binary_logloss: 0.000508137
Training until validation scores don&#39;t improve for 50 rounds
[LightGBM] [Debug] Re-bagging, using 125533 data to train
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
[2] valid_0&#39;s auc: 0.5  valid_0&#39;s binary_logloss: 0.000508137
[LightGBM] [Debug] Re-bagging, using 125272 data to train
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1
[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测结果重新排序, 及生成提交结果</span></span><br><span class="line">rank_results = tst_user_item_feats_df_rank_model[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>]]</span><br><span class="line">rank_results[<span class="string">&#x27;click_article_id&#x27;</span>] = rank_results[<span class="string">&#x27;click_article_id&#x27;</span>].astype(<span class="built_in">int</span>)</span><br><span class="line">submit(rank_results, topk=<span class="number">5</span>, model_name=<span class="string">&#x27;lgb_cls&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="dindeep-interest-network">DIN(Deep Interest Network)</h2>
<h3 id="din-简介">DIN 简介</h3>
<p>Deep Interest Network， 这是阿里2018年基于前面的深度学习模型无法表达用户多样化的兴趣而提出的一个模型， 它可以通过考虑【给定的候选广告】和【用户的历史行为】的相关性，来计算用户兴趣的表示向量。具体来说就是通过引入局部激活单元，通过软搜索历史行为的相关部分来关注相关的用户兴趣，并采用加权和来获得有关候选广告的用户兴趣的表示。与候选广告相关性较高的行为会获得较高的激活权重，并支配着用户兴趣。该表示向量在不同广告上有所不同，大大提高了模型的表达能力。所以该模型对于此次新闻推荐的任务也比较适合， 我们在这里通过当前的候选文章与用户历史点击文章的相关性来计算用户对于文章的兴趣。 该模型的结构如下： <img src="/img/din.png" /></p>
<p>直接调用包来使用这个模型，DIN模型函数原型如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">def DIN(dnn_feature_columns, history_feature_list, dnn_use_bn&#x3D;False, dnn_hidden_units&#x3D;(200, 80), dnn_activation&#x3D;&#39;relu&#39;, att_hidden_size&#x3D;(80, 40), att_activation&#x3D;&quot;dice&quot;, att_weight_normalization&#x3D;False, l2_reg_dnn&#x3D;0, l2_reg_embedding&#x3D;1e-6, dnn_dropout&#x3D;0, seed&#x3D;1024, task&#x3D;&#39;binary&#39;):</span><br><span class="line"></span><br><span class="line">    · dnn_feature_columns: 特征列， 包含数据所有特征的列表</span><br><span class="line">    · history_feature_list: 用户历史行为列， 反应用户历史行为的特征的列表</span><br><span class="line">    · dnn_use_bn: 是否使用BatchNormalization</span><br><span class="line">    · dnn_hidden_units: 全连接层网络的层数和每一层神经元的个数， 一个列表或者元组</span><br><span class="line">    · dnn_activation_relu: 全连接网络的激活单元类型</span><br><span class="line">    · att_hidden_size: 注意力层的全连接网络的层数和每一层神经元的个数</span><br><span class="line">    · att_activation: 注意力层的激活单元类型</span><br><span class="line">    · att_weight_normalization: 是否归一化注意力得分</span><br><span class="line">    · l2_reg_dnn: 全连接网络的正则化系数</span><br><span class="line">    · l2_reg_embedding: embedding向量的正则化稀疏</span><br><span class="line">    · dnn_dropout: 全连接网络的神经元的失活概率</span><br><span class="line">    · task: 任务， 可以是分类， 也可是是回归</span><br></pre></td></tr></table></figure>
<h3 id="使用din">使用DIN</h3>
<p>在具体使用的时候，必须要传入特征列和历史行为列，但是在传入之前，需要进行一下特征列的预处理。具体如下： 1. 首先，我们要处理数据集， 得到数据， 由于我们是基于用户过去的行为去预测用户是否点击当前文章， 所以我们需要把数据的特征列划分成数值型特征， 离散型特征和历史行为特征列三部分， 对于每一部分， DIN模型的处理会有不同 * 对于离散型特征， 在我们的数据集中就是那些类别型的特征， 比如user_id这种， 这种类别型特征， 我们首先要经过embedding处理得到每个特征的低维稠密型表示， 既然要经过embedding， 那么我们就需要为每一列的类别特征的取值建立一个字典，并指明embedding维度， 所以在使用deepctr的DIN模型准备数据的时候， 我们需要通过SparseFeat函数指明这些类别型特征, 这个函数的传入参数就是列名， 列的唯一取值(建立字典用)和embedding维度。 * 对于用户历史行为特征列， 比如文章id， 文章的类别等这种， 同样的我们需要先经过embedding处理， 只不过和上面不一样的地方是，对于这种特征， 我们在得到每个特征的embedding表示之后， 还需要通过一个Attention_layer计算用户的历史行为和当前候选文章的相关性以此得到当前用户的embedding向量， 这个向量就可以基于当前的候选文章与用户过去点击过得历史文章的相似性的程度来反应用户的兴趣， 并且随着用户的不同的历史点击来变化，去动态的模拟用户兴趣的变化过程。这类特征对于每个用户都是一个历史行为序列， 对于每个用户， 历史行为序列长度会不一样， 可能有的用户点击的历史文章多，有的点击的历史文章少， 所以我们还需要把这个长度统一起来， 在为DIN模型准备数据的时候， 我们首先要通过SparseFeat函数指明这些类别型特征， 然后还需要通过VarLenSparseFeat函数再进行序列填充， 使得每个用户的历史序列一样长， 所以这个函数参数中会有个maxlen，来指明序列的最大长度是多少。 * 对于连续型特征列， 我们只需要用DenseFeat函数来指明列名和维度即可。 2. 处理完特征列之后， 我们把相应的数据与列进行对应，就得到了最后的数据。</p>
<h3 id="用户的历史点击行为列表">用户的历史点击行为列表</h3>
<blockquote>
<p>为下面的DIN模型服务</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> offline:</span><br><span class="line">    all_data = pd.read_csv(<span class="string">&#x27;./raw_data/train_click_log.csv&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    trn_data = pd.read_csv(<span class="string">&#x27;./raw_data/train_click_log.csv&#x27;</span>)</span><br><span class="line">    tst_data = pd.read_csv(<span class="string">&#x27;./raw_data/testA_click_log.csv&#x27;</span>)</span><br><span class="line">    all_data = trn_data.append(tst_data)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hist_click =all_data[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>]].groupby(<span class="string">&#x27;user_id&#x27;</span>).agg(&#123;<span class="built_in">list</span>&#125;).reset_index()</span><br><span class="line">his_behavior_df = pd.DataFrame()</span><br><span class="line">his_behavior_df[<span class="string">&#x27;user_id&#x27;</span>] = hist_click[<span class="string">&#x27;user_id&#x27;</span>]</span><br><span class="line">his_behavior_df[<span class="string">&#x27;hist_click_article_id&#x27;</span>] = hist_click[<span class="string">&#x27;click_article_id&#x27;</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">trn_user_item_feats_df_din_model = trn_user_item_feats_df.copy()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> offline:</span><br><span class="line">    val_user_item_feats_df_din_model = val_user_item_feats_df.copy()</span><br><span class="line"><span class="keyword">else</span>: </span><br><span class="line">    val_user_item_feats_df_din_model = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">tst_user_item_feats_df_din_model = tst_user_item_feats_df.copy()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">trn_user_item_feats_df_din_model = trn_user_item_feats_df_din_model.merge(his_behavior_df, on=<span class="string">&#x27;user_id&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> offline:</span><br><span class="line">    val_user_item_feats_df_din_model = val_user_item_feats_df_din_model.merge(his_behavior_df, on=<span class="string">&#x27;user_id&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    val_user_item_feats_df_din_model = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">tst_user_item_feats_df_din_model = tst_user_item_feats_df_din_model.merge(his_behavior_df, on=<span class="string">&#x27;user_id&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="din的使用">DIN的使用</h3>
<p>首先写一个数据准备函数(根据上面的具体步骤准备数据)，得到数据和特征列，然后就是建立DIN模型并训练，最后基于模型进行测试。</p>
<blockquote>
<p>DIN模型训练存在Bug:InvalidArgumentError: indices[0,0] = 117303 is not in [0, 50001)--node sparse_emb_user_id_1/embedding_lookup (暂未解决，所以后面模型融合中关于DIN模型的都修改掉了。)</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入deepctr</span></span><br><span class="line"><span class="keyword">from</span> deepctr.models <span class="keyword">import</span> DIN</span><br><span class="line"><span class="keyword">from</span> deepctr.feature_column <span class="keyword">import</span> SparseFeat, VarLenSparseFeat, DenseFeat, get_feature_names</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.callbacks <span class="keyword">import</span> * </span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&quot;CUDA_DEVICE_ORDER&quot;</span>] = <span class="string">&quot;PCI_BUS_ID&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;0,1&quot;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据准备函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_din_feats_columns</span>(<span class="params">df, dense_fea, sparse_fea, behavior_fea, his_behavior_fea, emb_dim=<span class="number">32</span>, max_len=<span class="number">100</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    数据准备函数:</span></span><br><span class="line"><span class="string">    df: 数据集</span></span><br><span class="line"><span class="string">    dense_fea: 数值型特征列</span></span><br><span class="line"><span class="string">    sparse_fea: 离散型特征列</span></span><br><span class="line"><span class="string">    behavior_fea: 用户的候选行为特征列</span></span><br><span class="line"><span class="string">    his_behavior_fea: 用户的历史行为特征列</span></span><br><span class="line"><span class="string">    embedding_dim: embedding的维度， 这里为了简单， 统一把离散型特征列采用一样的隐向量维度</span></span><br><span class="line"><span class="string">    max_len: 用户序列的最大长度</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    sparse_feature_columns = [SparseFeat(feat, vocabulary_size=df[feat].nunique() + <span class="number">1</span>, embedding_dim=emb_dim) <span class="keyword">for</span> feat <span class="keyword">in</span> sparse_fea]</span><br><span class="line">    </span><br><span class="line">    dense_feature_columns = [DenseFeat(feat, <span class="number">1</span>, ) <span class="keyword">for</span> feat <span class="keyword">in</span> dense_fea]</span><br><span class="line">    </span><br><span class="line">    var_feature_columns = [VarLenSparseFeat(SparseFeat(feat, vocabulary_size=df[<span class="string">&#x27;click_article_id&#x27;</span>].nunique() + <span class="number">1</span>,</span><br><span class="line">                                    embedding_dim=emb_dim, embedding_name=<span class="string">&#x27;click_article_id&#x27;</span>), maxlen=max_len) <span class="keyword">for</span> feat <span class="keyword">in</span> hist_behavior_fea]</span><br><span class="line">    </span><br><span class="line">    dnn_feature_columns = sparse_feature_columns + dense_feature_columns + var_feature_columns</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 建立x, x是一个字典的形式</span></span><br><span class="line">    x = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> get_feature_names(dnn_feature_columns):</span><br><span class="line">        <span class="keyword">if</span> name <span class="keyword">in</span> his_behavior_fea:</span><br><span class="line">            <span class="comment"># 这是历史行为序列</span></span><br><span class="line">            his_list = [l <span class="keyword">for</span> l <span class="keyword">in</span> df[name]]</span><br><span class="line">            x[name] = pad_sequences(his_list, maxlen=max_len, padding=<span class="string">&#x27;post&#x27;</span>)      <span class="comment"># 二维数组</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            x[name] = df[name].values</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> x, dnn_feature_columns</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 把特征分开</span></span><br><span class="line">sparse_fea = [<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;category_id&#x27;</span>, <span class="string">&#x27;click_environment&#x27;</span>, <span class="string">&#x27;click_deviceGroup&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;click_os&#x27;</span>, <span class="string">&#x27;click_country&#x27;</span>, <span class="string">&#x27;click_region&#x27;</span>, <span class="string">&#x27;click_referrer_type&#x27;</span>, <span class="string">&#x27;is_cat_hab&#x27;</span>]</span><br><span class="line"></span><br><span class="line">behavior_fea = [<span class="string">&#x27;click_article_id&#x27;</span>]</span><br><span class="line"></span><br><span class="line">hist_behavior_fea = [<span class="string">&#x27;hist_click_article_id&#x27;</span>]</span><br><span class="line"></span><br><span class="line">dense_fea = [<span class="string">&#x27;sim0&#x27;</span>, <span class="string">&#x27;time_diff0&#x27;</span>, <span class="string">&#x27;word_diff0&#x27;</span>, <span class="string">&#x27;sim_max&#x27;</span>, <span class="string">&#x27;sim_min&#x27;</span>, <span class="string">&#x27;sim_sum&#x27;</span>, <span class="string">&#x27;sim_mean&#x27;</span>, <span class="string">&#x27;score&#x27;</span>,</span><br><span class="line">             <span class="string">&#x27;rank&#x27;</span>,<span class="string">&#x27;click_size&#x27;</span>,<span class="string">&#x27;time_diff_mean&#x27;</span>,<span class="string">&#x27;active_level&#x27;</span>,<span class="string">&#x27;user_time_hob1&#x27;</span>,<span class="string">&#x27;user_time_hob2&#x27;</span>,</span><br><span class="line">             <span class="string">&#x27;words_hbo&#x27;</span>,<span class="string">&#x27;words_count&#x27;</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dense特征进行归一化, 神经网络训练都需要将数值进行归一化处理</span></span><br><span class="line">mm = MinMaxScaler()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面是做一些特殊处理，当在其他的地方出现无效值的时候，不处理无法进行归一化，刚开始可以先把他注释掉，在运行了下面的代码</span></span><br><span class="line"><span class="comment"># 之后如果发现报错，应该先去想办法处理如何不出现inf之类的值</span></span><br><span class="line">trn_user_item_feats_df_din_model.replace([np.inf, -np.inf], <span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">tst_user_item_feats_df_din_model.replace([np.inf, -np.inf], <span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> dense_fea:</span><br><span class="line">    trn_user_item_feats_df_din_model[feat] = mm.fit_transform(trn_user_item_feats_df_din_model[[feat]])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> val_user_item_feats_df_din_model <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        val_user_item_feats_df_din_model[feat] = mm.fit_transform(val_user_item_feats_df_din_model[[feat]])</span><br><span class="line">    </span><br><span class="line">    tst_user_item_feats_df_din_model[feat] = mm.fit_transform(tst_user_item_feats_df_din_model[[feat]])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 准备训练数据</span></span><br><span class="line">x_trn, dnn_feature_columns = get_din_feats_columns(trn_user_item_feats_df_din_model, dense_fea, </span><br><span class="line">                                               sparse_fea, behavior_fea, hist_behavior_fea, max_len=<span class="number">50</span>)</span><br><span class="line">y_trn = trn_user_item_feats_df_din_model[<span class="string">&#x27;label&#x27;</span>].values</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> offline:</span><br><span class="line">    <span class="comment"># 准备验证数据</span></span><br><span class="line">    x_val, dnn_feature_columns = get_din_feats_columns(val_user_item_feats_df_din_model, dense_fea, </span><br><span class="line">                                                   sparse_fea, behavior_fea, hist_behavior_fea, max_len=<span class="number">50</span>)</span><br><span class="line">    y_val = val_user_item_feats_df_din_model[<span class="string">&#x27;label&#x27;</span>].values</span><br><span class="line">    </span><br><span class="line">dense_fea = [x <span class="keyword">for</span> x <span class="keyword">in</span> dense_fea <span class="keyword">if</span> x != <span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">x_tst, dnn_feature_columns = get_din_feats_columns(tst_user_item_feats_df_din_model, dense_fea, </span><br><span class="line">                                               sparse_fea, behavior_fea, hist_behavior_fea, max_len=<span class="number">50</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 建立模型</span></span><br><span class="line">model = DIN(dnn_feature_columns, behavior_fea)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看模型结构</span></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型编译</span></span><br><span class="line">model.<span class="built_in">compile</span>(<span class="string">&#x27;adam&#x27;</span>, <span class="string">&#x27;binary_crossentropy&#x27;</span>,metrics=[<span class="string">&#x27;binary_crossentropy&#x27;</span>, tf.keras.metrics.AUC()])</span><br><span class="line"><span class="comment"># model.compile(&#x27;adam&#x27;, &#x27;binary_crossentropy&#x27;,metrics=[&#x27;binary_crossentropy&#x27;, tf.metrics.auc()])</span></span><br></pre></td></tr></table></figure>
<pre><code>WARNING:tensorflow:Entity &lt;bound method NoMask.call of &lt;deepctr.layers.utils.NoMask object at 0x7f5ec0ba6e48&gt;&gt; could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting &lt;bound method NoMask.call of &lt;deepctr.layers.utils.NoMask object at 0x7f5ec0ba6e48&gt;&gt;: AssertionError: Bad argument number for Name: 3, expecting 4


WARNING:tensorflow:Entity &lt;bound method NoMask.call of &lt;deepctr.layers.utils.NoMask object at 0x7f5ec0ba6e48&gt;&gt; could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting &lt;bound method NoMask.call of &lt;deepctr.layers.utils.NoMask object at 0x7f5ec0ba6e48&gt;&gt;: AssertionError: Bad argument number for Name: 3, expecting 4


WARNING: Entity &lt;bound method NoMask.call of &lt;deepctr.layers.utils.NoMask object at 0x7f5ec0ba6e48&gt;&gt; could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting &lt;bound method NoMask.call of &lt;deepctr.layers.utils.NoMask object at 0x7f5ec0ba6e48&gt;&gt;: AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity &lt;bound method NoMask.call of &lt;deepctr.layers.utils.NoMask object at 0x7f5ec0ba6e48&gt;&gt; could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting &lt;bound method NoMask.call of &lt;deepctr.layers.utils.NoMask object at 0x7f5ec0ba6e48&gt;&gt;: AssertionError: Bad argument number for Name: 3, expecting 4


WARNING:tensorflow:Entity &lt;bound method NoMask.call of &lt;deepctr.layers.utils.NoMask object at 0x7f5ec0ba6e48&gt;&gt; could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting &lt;bound method NoMask.call of &lt;deepctr.layers.utils.NoMask object at 0x7f5ec0ba6e48&gt;&gt;: AssertionError: Bad argument number for Name: 3, expecting 4

WARNING: Entity &lt;bound method PredictionLayer.call of &lt;deepctr.layers.core.PredictionLayer object at 0x7f5ec05f14e0&gt;&gt; could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting &lt;bound method PredictionLayer.call of &lt;deepctr.layers.core.PredictionLayer object at 0x7f5ec05f14e0&gt;&gt;: AssertionError: Bad argument number for Name: 3, expecting 4
Model: &quot;model_2&quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
user_id (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
click_article_id (InputLayer)   [(None, 1)]          0                                            
__________________________________________________________________________________________________
category_id (InputLayer)        [(None, 1)]          0                                            
__________________________________________________________________________________________________
click_environment (InputLayer)  [(None, 1)]          0                                            
__________________________________________________________________________________________________
click_deviceGroup (InputLayer)  [(None, 1)]          0                                            
__________________________________________________________________________________________________
click_os (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
click_country (InputLayer)      [(None, 1)]          0                                            
__________________________________________________________________________________________________
click_region (InputLayer)       [(None, 1)]          0                                            
__________________________________________________________________________________________________
click_referrer_type (InputLayer [(None, 1)]          0                                            
__________________________________________________________________________________________________
is_cat_hab (InputLayer)         [(None, 1)]          0                                            
__________________________________________________________________________________________________
sparse_emb_user_id (Embedding)  (None, 1, 32)        1600032     user_id[0][0]                    
__________________________________________________________________________________________________
sparse_seq_emb_hist_click_artic multiple             503680      click_article_id[0][0]           
                                                                 hist_click_article_id[0][0]      
                                                                 click_article_id[0][0]           
__________________________________________________________________________________________________
sparse_emb_category_id (Embeddi (None, 1, 32)        1280        category_id[0][0]                
__________________________________________________________________________________________________
sparse_emb_click_environment (E (None, 1, 32)        128         click_environment[0][0]          
__________________________________________________________________________________________________
sparse_emb_click_deviceGroup (E (None, 1, 32)        160         click_deviceGroup[0][0]          
__________________________________________________________________________________________________
sparse_emb_click_os (Embedding) (None, 1, 32)        288         click_os[0][0]                   
__________________________________________________________________________________________________
sparse_emb_click_country (Embed (None, 1, 32)        384         click_country[0][0]              
__________________________________________________________________________________________________
sparse_emb_click_region (Embedd (None, 1, 32)        928         click_region[0][0]               
__________________________________________________________________________________________________
sparse_emb_click_referrer_type  (None, 1, 32)        256         click_referrer_type[0][0]        
__________________________________________________________________________________________________
sparse_emb_is_cat_hab (Embeddin (None, 1, 32)        64          is_cat_hab[0][0]                 
__________________________________________________________________________________________________
no_mask_10 (NoMask)             (None, 1, 32)        0           sparse_emb_user_id[0][0]         
                                                                 sparse_seq_emb_hist_click_article
                                                                 sparse_emb_category_id[0][0]     
                                                                 sparse_emb_click_environment[0][0
                                                                 sparse_emb_click_deviceGroup[0][0
                                                                 sparse_emb_click_os[0][0]        
                                                                 sparse_emb_click_country[0][0]   
                                                                 sparse_emb_click_region[0][0]    
                                                                 sparse_emb_click_referrer_type[0]
                                                                 sparse_emb_is_cat_hab[0][0]      
__________________________________________________________________________________________________
hist_click_article_id (InputLay [(None, 50)]         0                                            
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 1, 320)       0           no_mask_10[0][0]                 
                                                                 no_mask_10[1][0]                 
                                                                 no_mask_10[2][0]                 
                                                                 no_mask_10[3][0]                 
                                                                 no_mask_10[4][0]                 
                                                                 no_mask_10[5][0]                 
                                                                 no_mask_10[6][0]                 
                                                                 no_mask_10[7][0]                 
                                                                 no_mask_10[8][0]                 
                                                                 no_mask_10[9][0]                 
__________________________________________________________________________________________________
no_mask_11 (NoMask)             (None, 1, 320)       0           concatenate_8[0][0]              
__________________________________________________________________________________________________
attention_sequence_pooling_laye (None, 1, 32)        13961       sparse_seq_emb_hist_click_article
                                                                 sparse_seq_emb_hist_click_article
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 1, 352)       0           no_mask_11[0][0]                 
                                                                 attention_sequence_pooling_layer_
__________________________________________________________________________________________________
sim0 (InputLayer)               [(None, 1)]          0                                            
__________________________________________________________________________________________________
time_diff0 (InputLayer)         [(None, 1)]          0                                            
__________________________________________________________________________________________________
word_diff0 (InputLayer)         [(None, 1)]          0                                            
__________________________________________________________________________________________________
sim_max (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
sim_min (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
sim_sum (InputLayer)            [(None, 1)]          0                                            
__________________________________________________________________________________________________
sim_mean (InputLayer)           [(None, 1)]          0                                            
__________________________________________________________________________________________________
score (InputLayer)              [(None, 1)]          0                                            
__________________________________________________________________________________________________
rank (InputLayer)               [(None, 1)]          0                                            
__________________________________________________________________________________________________
click_size (InputLayer)         [(None, 1)]          0                                            
__________________________________________________________________________________________________
time_diff_mean (InputLayer)     [(None, 1)]          0                                            
__________________________________________________________________________________________________
active_level (InputLayer)       [(None, 1)]          0                                            
__________________________________________________________________________________________________
user_time_hob1 (InputLayer)     [(None, 1)]          0                                            
__________________________________________________________________________________________________
user_time_hob2 (InputLayer)     [(None, 1)]          0                                            
__________________________________________________________________________________________________
words_hbo (InputLayer)          [(None, 1)]          0                                            
__________________________________________________________________________________________________
words_count (InputLayer)        [(None, 1)]          0                                            
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 352)          0           concatenate_9[0][0]              
__________________________________________________________________________________________________
no_mask_13 (NoMask)             (None, 1)            0           sim0[0][0]                       
                                                                 time_diff0[0][0]                 
                                                                 word_diff0[0][0]                 
                                                                 sim_max[0][0]                    
                                                                 sim_min[0][0]                    
                                                                 sim_sum[0][0]                    
                                                                 sim_mean[0][0]                   
                                                                 score[0][0]                      
                                                                 rank[0][0]                       
                                                                 click_size[0][0]                 
                                                                 time_diff_mean[0][0]             
                                                                 active_level[0][0]               
                                                                 user_time_hob1[0][0]             
                                                                 user_time_hob2[0][0]             
                                                                 words_hbo[0][0]                  
                                                                 words_count[0][0]                
__________________________________________________________________________________________________
no_mask_12 (NoMask)             (None, 352)          0           flatten_6[0][0]                  
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 16)           0           no_mask_13[0][0]                 
                                                                 no_mask_13[1][0]                 
                                                                 no_mask_13[2][0]                 
                                                                 no_mask_13[3][0]                 
                                                                 no_mask_13[4][0]                 
                                                                 no_mask_13[5][0]                 
                                                                 no_mask_13[6][0]                 
                                                                 no_mask_13[7][0]                 
                                                                 no_mask_13[8][0]                 
                                                                 no_mask_13[9][0]                 
                                                                 no_mask_13[10][0]                
                                                                 no_mask_13[11][0]                
                                                                 no_mask_13[12][0]                
                                                                 no_mask_13[13][0]                
                                                                 no_mask_13[14][0]                
                                                                 no_mask_13[15][0]                
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 352)          0           no_mask_12[0][0]                 
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 16)           0           concatenate_10[0][0]             
__________________________________________________________________________________________________
no_mask_14 (NoMask)             multiple             0           flatten_7[0][0]                  
                                                                 flatten_8[0][0]                  
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 368)          0           no_mask_14[0][0]                 
                                                                 no_mask_14[1][0]                 
__________________________________________________________________________________________________
dnn_5 (DNN)                     (None, 80)           89880       concatenate_11[0][0]             
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            80          dnn_5[0][0]                      
__________________________________________________________________________________________________
prediction_layer_2 (PredictionL (None, 1)            1           dense_2[0][0]                    
==================================================================================================
Total params: 2,211,122
Trainable params: 2,210,882
Non-trainable params: 240
__________________________________________________________________________________________________</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line"><span class="keyword">if</span> offline:</span><br><span class="line">    history = model.fit(x_trn, y_trn, verbose=<span class="number">1</span>, epochs=<span class="number">10</span>, validation_data=(x_val, y_val) , batch_size=<span class="number">256</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 也可以使用上面的语句用自己采样出来的验证集</span></span><br><span class="line"><span class="comment">#     history = model.fit(x_trn, y_trn, verbose=1, epochs=3, validation_split=0.3, batch_size=256)</span></span><br><span class="line">    history = model.fit(x_trn, y_trn, batch_size=<span class="number">256</span>, epochs=<span class="number">2</span>, verbose=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">tst_user_item_feats_df_din_model[<span class="string">&#x27;pred_score&#x27;</span>] = model.predict(x_tst, verbose=<span class="number">1</span>, batch_size=<span class="number">256</span>)</span><br><span class="line">tst_user_item_feats_df_din_model[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>]].to_csv(save_path + <span class="string">&#x27;din_rank_score.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测结果重新排序, 及生成提交结果</span></span><br><span class="line">rank_results = tst_user_item_feats_df_din_model[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>]]</span><br><span class="line">submit(rank_results, topk=<span class="number">5</span>, model_name=<span class="string">&#x27;din&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 五折交叉验证，这里的五折交叉是以用户为目标进行五折划分</span></span><br><span class="line"><span class="comment">#  这一部分与前面的单独训练和验证是分开的</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_kfold_users</span>(<span class="params">trn_df, n=<span class="number">5</span></span>):</span></span><br><span class="line">    user_ids = trn_df[<span class="string">&#x27;user_id&#x27;</span>].unique()</span><br><span class="line">    user_set = [user_ids[i::n] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    <span class="keyword">return</span> user_set</span><br><span class="line"></span><br><span class="line">k_fold = <span class="number">5</span></span><br><span class="line">trn_df = trn_user_item_feats_df_din_model</span><br><span class="line">user_set = get_kfold_users(trn_df, n=k_fold)</span><br><span class="line"></span><br><span class="line">score_list = []</span><br><span class="line">score_df = trn_df[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;label&#x27;</span>]]</span><br><span class="line">sub_preds = np.zeros(tst_user_item_feats_df_rank_model.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">dense_fea = [x <span class="keyword">for</span> x <span class="keyword">in</span> dense_fea <span class="keyword">if</span> x != <span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">x_tst, dnn_feature_columns = get_din_feats_columns(tst_user_item_feats_df_din_model, dense_fea, </span><br><span class="line">                                                   sparse_fea, behavior_fea, hist_behavior_fea, max_len=<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 五折交叉验证，并将中间结果保存用于staking</span></span><br><span class="line"><span class="keyword">for</span> n_fold, valid_user <span class="keyword">in</span> <span class="built_in">enumerate</span>(user_set):</span><br><span class="line">    train_idx = trn_df[~trn_df[<span class="string">&#x27;user_id&#x27;</span>].isin(valid_user)] <span class="comment"># add slide user</span></span><br><span class="line">    valid_idx = trn_df[trn_df[<span class="string">&#x27;user_id&#x27;</span>].isin(valid_user)]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 准备训练数据</span></span><br><span class="line">    x_trn, dnn_feature_columns = get_din_feats_columns(train_idx, dense_fea, </span><br><span class="line">                                                       sparse_fea, behavior_fea, hist_behavior_fea, max_len=<span class="number">50</span>)</span><br><span class="line">    y_trn = train_idx[<span class="string">&#x27;label&#x27;</span>].values</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 准备验证数据</span></span><br><span class="line">    x_val, dnn_feature_columns = get_din_feats_columns(valid_idx, dense_fea, </span><br><span class="line">                                                   sparse_fea, behavior_fea, hist_behavior_fea, max_len=<span class="number">50</span>)</span><br><span class="line">    y_val = valid_idx[<span class="string">&#x27;label&#x27;</span>].values</span><br><span class="line">    </span><br><span class="line">    history = model.fit(x_trn, y_trn, verbose=<span class="number">1</span>, epochs=<span class="number">2</span>, validation_data=(x_val, y_val) , batch_size=<span class="number">256</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 预测验证集结果</span></span><br><span class="line">    valid_idx[<span class="string">&#x27;pred_score&#x27;</span>] = model.predict(x_val, verbose=<span class="number">1</span>, batch_size=<span class="number">256</span>)   </span><br><span class="line">    </span><br><span class="line">    valid_idx.sort_values(by=[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>])</span><br><span class="line">    valid_idx[<span class="string">&#x27;pred_rank&#x27;</span>] = valid_idx.groupby([<span class="string">&#x27;user_id&#x27;</span>])[<span class="string">&#x27;pred_score&#x27;</span>].rank(ascending=<span class="literal">False</span>, method=<span class="string">&#x27;first&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将验证集的预测结果放到一个列表中，后面进行拼接</span></span><br><span class="line">    score_list.append(valid_idx[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>, <span class="string">&#x27;pred_rank&#x27;</span>]])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 如果是线上测试，需要计算每次交叉验证的结果相加，最后求平均</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> offline:</span><br><span class="line">        sub_preds += model.predict(x_tst, verbose=<span class="number">1</span>, batch_size=<span class="number">256</span>)[:, <span class="number">0</span>]   </span><br><span class="line">    </span><br><span class="line">score_df_ = pd.concat(score_list, axis=<span class="number">0</span>)</span><br><span class="line">score_df = score_df.merge(score_df_, how=<span class="string">&#x27;left&#x27;</span>, on=[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>])</span><br><span class="line"><span class="comment"># 保存训练集交叉验证产生的新特征</span></span><br><span class="line">score_df[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>, <span class="string">&#x27;pred_rank&#x27;</span>, <span class="string">&#x27;label&#x27;</span>]].to_csv(save_path + <span class="string">&#x27;trn_din_cls_feats.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试集的预测结果，多次交叉验证求平均,将预测的score和对应的rank特征保存，可以用于后面的staking，这里还可以构造其他更多的特征</span></span><br><span class="line">tst_user_item_feats_df_din_model[<span class="string">&#x27;pred_score&#x27;</span>] = sub_preds / k_fold</span><br><span class="line">tst_user_item_feats_df_din_model[<span class="string">&#x27;pred_score&#x27;</span>] = tst_user_item_feats_df_din_model[<span class="string">&#x27;pred_score&#x27;</span>].transform(<span class="keyword">lambda</span> x: norm_sim(x))</span><br><span class="line">tst_user_item_feats_df_din_model.sort_values(by=[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>])</span><br><span class="line">tst_user_item_feats_df_din_model[<span class="string">&#x27;pred_rank&#x27;</span>] = tst_user_item_feats_df_din_model.groupby([<span class="string">&#x27;user_id&#x27;</span>])[<span class="string">&#x27;pred_score&#x27;</span>].rank(ascending=<span class="literal">False</span>, method=<span class="string">&#x27;first&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存测试集交叉验证的新特征</span></span><br><span class="line">tst_user_item_feats_df_din_model[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>, <span class="string">&#x27;pred_rank&#x27;</span>]].to_csv(save_path + <span class="string">&#x27;tst_din_cls_feats.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h2 id="模型融合">模型融合</h2>
<h3 id="加权融合">加权融合</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取多个模型的排序结果文件</span></span><br><span class="line">lgb_ranker = pd.read_csv(save_path + <span class="string">&#x27;lgb_ranker_score.csv&#x27;</span>)</span><br><span class="line">lgb_cls = pd.read_csv(save_path + <span class="string">&#x27;lgb_cls_score.csv&#x27;</span>)</span><br><span class="line"><span class="comment"># din_ranker = pd.read_csv(save_path + &#x27;din_rank_score.csv&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里也可以换成交叉验证输出的测试结果进行加权融合</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rank_model = &#123;&#x27;lgb_ranker&#x27;: lgb_ranker, </span></span><br><span class="line"><span class="comment">#               &#x27;lgb_cls&#x27;: lgb_cls, </span></span><br><span class="line"><span class="comment">#               &#x27;din_ranker&#x27;: din_ranker&#125;</span></span><br><span class="line">rank_model = &#123;<span class="string">&#x27;lgb_ranker&#x27;</span>: lgb_ranker, </span><br><span class="line">              <span class="string">&#x27;lgb_cls&#x27;</span>: lgb_cls&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_ensumble_predict_topk</span>(<span class="params">rank_model, topk=<span class="number">5</span></span>):</span></span><br><span class="line"><span class="comment">#     final_recall = rank_model[&#x27;lgb_cls&#x27;].append(rank_model[&#x27;din_ranker&#x27;])</span></span><br><span class="line">    final_recall = rank_model[<span class="string">&#x27;lgb_cls&#x27;</span>]</span><br><span class="line">    rank_model[<span class="string">&#x27;lgb_ranker&#x27;</span>][<span class="string">&#x27;pred_score&#x27;</span>] = rank_model[<span class="string">&#x27;lgb_ranker&#x27;</span>][<span class="string">&#x27;pred_score&#x27;</span>].transform(<span class="keyword">lambda</span> x: norm_sim(x))</span><br><span class="line">    </span><br><span class="line">    final_recall = final_recall.append(rank_model[<span class="string">&#x27;lgb_ranker&#x27;</span>])</span><br><span class="line">    final_recall = final_recall.groupby([<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>])[<span class="string">&#x27;pred_score&#x27;</span>].<span class="built_in">sum</span>().reset_index()</span><br><span class="line">    </span><br><span class="line">    submit(final_recall, topk=topk, model_name=<span class="string">&#x27;ensemble_fuse&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">get_ensumble_predict_topk(rank_model)</span><br></pre></td></tr></table></figure>
<h3 id="stacking">Stacking</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取多个模型的交叉验证生成的结果文件</span></span><br><span class="line"><span class="comment"># 训练集</span></span><br><span class="line">trn_lgb_ranker_feats = pd.read_csv(save_path + <span class="string">&#x27;trn_lgb_ranker_feats.csv&#x27;</span>)</span><br><span class="line">trn_lgb_cls_feats = pd.read_csv(save_path + <span class="string">&#x27;trn_lgb_cls_feats.csv&#x27;</span>)</span><br><span class="line"><span class="comment"># trn_din_cls_feats = pd.read_csv(save_path + &#x27;trn_din_cls_feats.csv&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试集</span></span><br><span class="line">tst_lgb_ranker_feats = pd.read_csv(save_path + <span class="string">&#x27;tst_lgb_ranker_feats.csv&#x27;</span>)</span><br><span class="line">tst_lgb_cls_feats = pd.read_csv(save_path + <span class="string">&#x27;tst_lgb_cls_feats.csv&#x27;</span>)</span><br><span class="line"><span class="comment"># tst_din_cls_feats = pd.read_csv(save_path + &#x27;tst_din_cls_feats.csv&#x27;)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将多个模型输出的特征进行拼接</span></span><br><span class="line"></span><br><span class="line">finall_trn_ranker_feats = trn_lgb_ranker_feats[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;label&#x27;</span>]]</span><br><span class="line">finall_tst_ranker_feats = tst_lgb_ranker_feats[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>]]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx, trn_model <span class="keyword">in</span> <span class="built_in">enumerate</span>([trn_lgb_ranker_feats, trn_lgb_cls_feats]):</span><br><span class="line">    <span class="keyword">for</span> feat <span class="keyword">in</span> [ <span class="string">&#x27;pred_score&#x27;</span>, <span class="string">&#x27;pred_rank&#x27;</span>]:</span><br><span class="line">        col_name = feat + <span class="string">&#x27;_&#x27;</span> + <span class="built_in">str</span>(idx)</span><br><span class="line">        finall_trn_ranker_feats[col_name] = trn_model[feat]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx, tst_model <span class="keyword">in</span> <span class="built_in">enumerate</span>([tst_lgb_ranker_feats, tst_lgb_cls_feats]):</span><br><span class="line">    <span class="keyword">for</span> feat <span class="keyword">in</span> [ <span class="string">&#x27;pred_score&#x27;</span>, <span class="string">&#x27;pred_rank&#x27;</span>]:</span><br><span class="line">        col_name = feat + <span class="string">&#x27;_&#x27;</span> + <span class="built_in">str</span>(idx)</span><br><span class="line">        finall_tst_ranker_feats[col_name] = tst_model[feat]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个逻辑回归模型再次拟合交叉验证产生的特征对测试集进行预测</span></span><br><span class="line"><span class="comment"># 这里需要注意的是，在做交叉验证的时候可以构造多一些与输出预测值相关的特征，来丰富这里简单模型的特征</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line"><span class="comment"># feat_cols = [&#x27;pred_score_0&#x27;, &#x27;pred_rank_0&#x27;, &#x27;pred_score_1&#x27;, &#x27;pred_rank_1&#x27;, &#x27;pred_score_2&#x27;, &#x27;pred_rank_2&#x27;]</span></span><br><span class="line">feat_cols = [<span class="string">&#x27;pred_score_0&#x27;</span>, <span class="string">&#x27;pred_rank_0&#x27;</span>, <span class="string">&#x27;pred_score_1&#x27;</span>, <span class="string">&#x27;pred_rank_1&#x27;</span>]</span><br><span class="line"></span><br><span class="line">trn_x = finall_trn_ranker_feats[feat_cols]</span><br><span class="line">trn_y = finall_trn_ranker_feats[<span class="string">&#x27;label&#x27;</span>]</span><br><span class="line"></span><br><span class="line">tst_x = finall_tst_ranker_feats[feat_cols]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型</span></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">lr.fit(trn_x, trn_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">finall_tst_ranker_feats[<span class="string">&#x27;pred_score&#x27;</span>] = lr.predict_proba(tst_x)[:, <span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测结果重新排序, 及生成提交结果</span></span><br><span class="line">rank_results = finall_tst_ranker_feats[[<span class="string">&#x27;user_id&#x27;</span>, <span class="string">&#x27;click_article_id&#x27;</span>, <span class="string">&#x27;pred_score&#x27;</span>]]</span><br><span class="line">submit(rank_results, topk=<span class="number">5</span>, model_name=<span class="string">&#x27;ensumble_staking&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="总结">总结</h2>
<ul>
<li>三个排序模型包括LGB的Rank， LGB的Classifier还有深度学习的DIN模型(DIN模型训练问题暂未解决)。</li>
<li>简单的模型融合策略，包括简单的加权和Stacking。</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">李子梅</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://lzmcosmos.github.io/2020/12/06/%E5%A4%A9%E6%B1%A0%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90task4/">https://lzmcosmos.github.io/2020/12/06/%E5%A4%A9%E6%B1%A0%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90task4/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/12/09/AddOne/"><img class="prev-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">编程题--加一</div></div></a></div><div class="next-post pull-right"><a href="/2020/12/02/%E5%A4%A9%E6%B1%A0%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90task3/"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">天池-新闻推荐之特征工程</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="twikoo"></div></div></div></div></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/cosmos.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">李子梅</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">89</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">108</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">9</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/LZMcosmos"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/LZMcosmos" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:609792588@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">“莱布尼茨在他的二进位算术中看到了宇宙创始的原像。他想象1表示上帝，而0表示虚无，上帝从虚无中创造出所有实物，恰如在他的数学系统中用1和0表示了所有的数。”</div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="card-content"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.</span> <span class="toc-text">排序模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">1.1.</span> <span class="toc-text">排序模型的选择</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E7%9A%84%E6%A8%A1%E5%9E%8B%E9%9B%86%E6%88%90%E6%96%B9%E6%B3%95"><span class="toc-number">1.2.</span> <span class="toc-text">经典的模型集成方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E5%8C%85"><span class="toc-number">1.3.</span> <span class="toc-text">导入包</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96%E6%8E%92%E5%BA%8F%E7%89%B9%E5%BE%81"><span class="toc-number">1.4.</span> <span class="toc-text">读取排序特征</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%94%E5%9B%9E%E6%8E%92%E5%BA%8F%E5%90%8E%E7%9A%84%E7%BB%93%E6%9E%9C"><span class="toc-number">1.5.</span> <span class="toc-text">返回排序后的结果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lgb%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.6.</span> <span class="toc-text">LGB排序模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lgb%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.7.</span> <span class="toc-text">LGB分类模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#dindeep-interest-network"><span class="toc-number">1.8.</span> <span class="toc-text">DIN(Deep Interest Network)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#din-%E7%AE%80%E4%BB%8B"><span class="toc-number">1.8.1.</span> <span class="toc-text">DIN 简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8din"><span class="toc-number">1.8.2.</span> <span class="toc-text">使用DIN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%A8%E6%88%B7%E7%9A%84%E5%8E%86%E5%8F%B2%E7%82%B9%E5%87%BB%E8%A1%8C%E4%B8%BA%E5%88%97%E8%A1%A8"><span class="toc-number">1.8.3.</span> <span class="toc-text">用户的历史点击行为列表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#din%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">1.8.4.</span> <span class="toc-text">DIN的使用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88"><span class="toc-number">1.9.</span> <span class="toc-text">模型融合</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A0%E6%9D%83%E8%9E%8D%E5%90%88"><span class="toc-number">1.9.1.</span> <span class="toc-text">加权融合</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#stacking"><span class="toc-number">1.9.2.</span> <span class="toc-text">Stacking</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">1.10.</span> <span class="toc-text">总结</span></a></li></ol></li></ol></div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/03/13/Mysql%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E4%B8%8E%E5%85%A5%E9%97%A8/" title="MySQL环境搭建与入门">MySQL环境搭建与入门</a><time datetime="2022-03-13T01:08:47.000Z" title="Created 2022-03-13 09:08:47">2022-03-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/11/01/CRF/" title="条件随机场（CRF）">条件随机场（CRF）</a><time datetime="2021-11-01T03:28:44.000Z" title="Created 2021-11-01 11:28:44">2021-11-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/07/14/%E5%AD%97%E7%AC%A6%E4%B8%B2/" title="字符串">字符串</a><time datetime="2021-07-13T16:30:25.000Z" title="Created 2021-07-14 00:30:25">2021-07-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/06/29/Heap/" title="堆">堆</a><time datetime="2021-06-29T04:45:04.000Z" title="Created 2021-06-29 12:45:04">2021-06-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/05/14/Stacking-of-Steam/" title="Stacking集成学习案例二：蒸汽量预测">Stacking集成学习案例二：蒸汽量预测</a><time datetime="2021-05-14T03:50:07.000Z" title="Created 2021-05-14 11:50:07">2021-05-14</time></div></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(/img/Nebula_planets-Universe.jpg)"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By 李子梅</div><div class="footer_custom_text">welcome to my <a href="https://lzmcosmos.github.io/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>function loadTwikoo () {
  function init () {
    twikoo.init({ 
      envId: 'lzm-blog-8gx8fhrs09a28b34' 
    })
  }

  if (typeof twikoo.init === 'function') {
    init()
  } else {
    $.getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js', init)
  }
}

if ('Twikoo' === 'Twikoo' || !false) {
  if (false) btf.loadComment(document.getElementById('twikoo'), loadTwikoo)
  else loadTwikoo()
} else {
  function loadOtherComment () {
    loadTwikoo()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script>(function(){
  const bp = document.createElement('script');
  const curProtocol = window.location.protocol.split(':')[0];
  if (curProtocol === 'https'){
  bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
  }
  else{
  bp.src = 'http://push.zhanzhang.baidu.com/push.js';
  }
  bp.dataset.pjax = ''
  const s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(bp, s);
})()</script></div></body></html>